# ì„ í˜• íšŒê·€ ëª¨ë¸ - ëª¨ë¸ ìƒì„± 3ê°€ì§€ ë³´ì—¬ì¤Œ 
# https://cafe.daum.net/flowlife/S2Ul/10  

import tensorflow as tf 
from tensorflow.keras.models import Sequential 
from tensorflow.keras.layers import Dense, Input   # ì¼€ë¼ìŠ¤ì˜ ê°€ì¥ ë ë ˆì´ì–´ëŠ” ë´ìŠ¤ë‹¤
from tensorflow.keras import optimizers 
import numpy as np 

# ê³µë¶€ì‹œê°„ì— ë”°ë¥¸ ì„±ì  ë°ì´í„° ì‚¬ìš© 
x_data = np.array([1,2,3,4,5],dtype=np.float32).reshape(-1,1)  # (5,1)
# x_data=[[1],[2],[3],[4],[5]] ì´ë ‡ê²Œ ì¨ë„ ë¨
y_data=np.array([11,32,53,64,70],dtype=np.float32).reshape(-1,1)   

# ëª¨ë¸ ìƒì„± ë°©ë²• 1 - Sequential API ì‚¬ìš© 
# ëª¨ë¸ êµ¬ì„±ì´ ìˆœì°¨ì [ë‹¨ìˆœí•œ] ê²½ìš°ì— ì‚¬ìš©
model=Sequential() # ê³„ì¸µ êµ¬ì¡°ì„(linear layer stack) 
model.add(Input((1,)))
model.add(Dense(units=16,activation='relu'))  # ì¤‘ê°„ì¸µì€ ReLU íˆë“ ì€ ë ë£¨ë¥¼ì¨ë¼, ê·¸ë˜ì•¼ mseì˜ ì†ì‹¤ê°’ì´ ë‚®ì•„ì§
model.add(Dense(units=1,activation='linear'))  # ì„ í˜•íšŒê·€ë‹ˆê¹Œ í™œì„±í™” í•¨ìˆ˜ëŠ” linear

print(model.summary()) # êµ¬ì¡° í™•ì¸ ê°€ëŠ¥ 

opti=optimizers.SGD(learning_rate=0.001)  # í™•ë¥ ì  ê²½ì‚¬í•˜ê°•ë²•  
model.compile(optimizer=opti,loss='mse',metrics=['mse'])  # ì”ì°¨ì— ëŒ€í•´ì„œ í‰ê· ì„ ì·¨í•œê°’ì„. 
# ì¶”ì¸¡ê°’ ì˜ˆì¸¡ê°’ì— ëŒ€í•œ ì •í™•ì„±ì„ ..í• ë•Œ mse ëŠ” 0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì¢‹ìŒ  

# í•™ìŠµì§„í–‰í• ë•Œ lossê°’ í™•ì¸í•˜ê³ ì‹¶ìœ¼ë©´ íˆìŠ¤í† ë¦¬
history=model.fit(x_data,y_data,epochs=100,batch_size=1,verbose=0) # ë‰´ëŸ´ë„¤íŠ¸ì›Œí¬ëŠ” ë¡œì§€ìŠ¤í‹±ë¦¬ê·¸ë ˆì…˜ì—ì„œ ë§ì´ ë•„ë‹¤
loss_metrics=model.evaluate(x=x_data,y=y_data,verbose=0)  # í•™ìŠµ/ê²€ì¦ ë°ì´í„°ë¥¼ ë‚˜ëˆ„ì§€ ì•Šì•˜ìœ¼ë‹ˆê¹Œ. í•™ìŠµ í›„ í‰ê°€
print('loss_metrics:',loss_metrics)  # loss: [mse, mse]

# ì„±ëŠ¥í™•ì¸í•´ë³´ê¸° 
from sklearn.metrics import r2_score 
y_pred=model.predict(x_data)  # ì˜ˆì¸¡ê°’ 
print('ì„¤ëª…ë ¥:',r2_score(y_data,y_pred))
print('ì‹¤ì œê°’:',y_data.ravel())
print('ì˜ˆì¸¡:',y_pred.ravel())

# ìƒˆ ë°ì´í„°(n,1)ë¡œ ì˜ˆì¸¡ 
new_data=np.array([1.5,2.2,5.8],dtype=np.float32).reshape(-1,1)
new_pred=model.predict(new_data).ravel()
print('ìƒˆ ë°ì´í„° ì˜ˆì¸¡:',new_pred)

# ì‹œê°í™” 
import matplotlib.pyplot as plt 
plt.plot(x_data.ravel(),y_pred.ravel(),'b',label='pred')  # ì˜ˆì¸¡ê°’
plt.plot(x_data.ravel(),y_data.ravel(),'ko',label='true')  # ì‹¤ì œê°’
plt.legend()
plt.show()

# ëª¨ë¸ ìƒì„± ë°©ë²• 2 - functional API ì‚¬ìš©  
# ìœ ì—°í•œêµ¬ì¡°, ì…ë ¥ë°ì´í„°ë¡œ ì—¬ëŸ¬ ì¸µì„ ê³µìœ , ë‹¤ì–‘í•œ ì¢…ë¥˜ì˜ ì…ì¶œë ¥ ê°€ëŠ¥ 
# multi-input model , multi-output model , ê³µìœ ì¸µ í™œìš© ëª¨ë¸, ë¹„ìˆœì°¨ì  ë°ì´í„° ì²˜ë¦¬... 
from tensorflow.keras import Model

# inputs=Input(shape=(1,)) # ì…ë ¥ì¸µ 
# outputs=Dense(units=1,activation='linear')(inputs) # ì¶œë ¥ì¸µ 

# model2=Model(inputs,outputs)  

# íˆë“  ë ˆì´ì–´ ì ìš©
inputs=Input(shape=(1,)) # ì…ë ¥ì¸µ 
outputs1=Dense(units=16,activation='relu')(inputs) 
outputs2=Dense(units=1,activation='linear')(outputs1) # ì´ì „ì¸µì„ ì ì–´ì¤Œ
model2=Model(inputs,outputs2) # ìµœì¢… ì¸í’‹,ì•„ì›ƒí’‹
# ì´ì „ì¸µì„ ë‹¤ìŒì¸µ í•¨ìˆ˜ì˜ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•˜ê¸° ìœ„í•´ ë³€ìˆ˜ì— í• ë‹¹ 

opti2=optimizers.SGD(learning_rate=0.001)  # í™•ë¥ ì  ê²½ì‚¬í•˜ê°•ë²•  
model2.compile(optimizer=opti2,loss='mse',metrics=['mse'])  # ì”ì°¨ì— ëŒ€í•´ì„œ í‰ê· ì„ ì·¨í•œê°’ì„. 
# ì¶”ì¸¡ê°’ ì˜ˆì¸¡ê°’ì— ëŒ€í•œ ì •í™•ì„±ì„ ..í• ë•Œ mse ëŠ” 0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì¢‹ìŒ  

# í•™ìŠµì§„í–‰í• ë•Œ lossê°’ í™•ì¸í•˜ê³ ì‹¶ìœ¼ë©´ íˆìŠ¤í† ë¦¬
history2=model2.fit(x_data,y_data,epochs=100,batch_size=1,verbose=0) # ë‰´ëŸ´ë„¤íŠ¸ì›Œí¬ëŠ” ë¡œì§€ìŠ¤í‹±ë¦¬ê·¸ë ˆì…˜ì—ì„œ ë§ì´ ë•„ë‹¤
loss_metrics=model2.evaluate(x=x_data,y=y_data,verbose=0)  # í•™ìŠµ/ê²€ì¦ ë°ì´í„°ë¥¼ ë‚˜ëˆ„ì§€ ì•Šì•˜ìœ¼ë‹ˆê¹Œ. í•™ìŠµ í›„ í‰ê°€
print('loss_metrics:',loss_metrics)  # loss: [mse, mse]

# ì„±ëŠ¥í™•ì¸í•´ë³´ê¸° 
from sklearn.metrics import r2_score 
y_pred2=model2.predict(x_data)  # ì˜ˆì¸¡ê°’ 
print('ì„¤ëª…ë ¥:',r2_score(y_data,y_pred2))
print('ì‹¤ì œê°’:',y_data.ravel())
print('ì˜ˆì¸¡:',y_pred2.ravel())

# https://cafe.daum.net/flowlife/S2Ul/68 
# ì´ˆë°˜ì—” ìƒ˜í”Œìˆ˜ ì ê²Œ ì‹œì‘í•˜ë¼. 

# ëª¨ë¸ ìƒì„± ë°©ë²• 3 - sub classing API ì‚¬ìš©, ê³ ë‚œì´ë„ ì‘ì—…ì—ì„œ í™œìš©ì„± ë†’ìŒ, ë™ì ì¸ êµ¬ì¡°ì— ì í•© 
class MyModel(Model):
    def __init__(self):
        super().__init__() # ë¶€ëª¨ì˜ inití˜¸ì¶œ
        self.d1=Dense(16,activation='relu')
        self.d2=Dense(1,activation='linear')
        
# xëŠ” input ë§¤ê°œë³€ìˆ˜. functional api ì™€ ìœ ì‚¬í•˜ë‚˜ Input ê°ì²´ë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
# ê³„ì‚°ì‘ì—…ë“±ì„ í•  ìˆ˜ ìˆë‹¤
# ì´ call ë©”ì„œë“œëŠ”, model.fit(),evaluate(),predict() í•˜ë©´ ìë™ í˜¸ì¶œë¨
    def call(self,x):  
        x=self.d1(x)
        return self.d2(x) #  ì´ì „ì¸µ ë‹´ìŒ

model3=MyModel() 

opti3=optimizers.SGD(learning_rate=0.001)  # í™•ë¥ ì  ê²½ì‚¬í•˜ê°•ë²•  
model3.compile(optimizer=opti3,loss='mse',metrics=['mse'])  # ì”ì°¨ì— ëŒ€í•´ì„œ í‰ê· ì„ ì·¨í•œê°’ì„. 
# ì¶”ì¸¡ê°’ ì˜ˆì¸¡ê°’ì— ëŒ€í•œ ì •í™•ì„±ì„ ..í• ë•Œ mse ëŠ” 0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì¢‹ìŒ  

# í•™ìŠµì§„í–‰í• ë•Œ lossê°’ í™•ì¸í•˜ê³ ì‹¶ìœ¼ë©´ íˆìŠ¤í† ë¦¬
history3=model3.fit(x_data,y_data,epochs=100,batch_size=1,verbose=0) # ë‰´ëŸ´ë„¤íŠ¸ì›Œí¬ëŠ” ë¡œì§€ìŠ¤í‹±ë¦¬ê·¸ë ˆì…˜ì—ì„œ ë§ì´ ë•„ë‹¤
loss_metrics3=model3.evaluate(x=x_data,y=y_data,verbose=0)  # í•™ìŠµ/ê²€ì¦ ë°ì´í„°ë¥¼ ë‚˜ëˆ„ì§€ ì•Šì•˜ìœ¼ë‹ˆê¹Œ. í•™ìŠµ í›„ í‰ê°€
print('loss_metrics:',loss_metrics3)  # loss: [mse, mse]

# ì„±ëŠ¥í™•ì¸í•´ë³´ê¸° 
from sklearn.metrics import r2_score 
y_pred3=model3.predict(x_data)  # ì˜ˆì¸¡ê°’ 
print('ì„¤ëª…ë ¥:',r2_score(y_data,y_pred3))
print('ì‹¤ì œê°’:',y_data.ravel())
print('ì˜ˆì¸¡:',y_pred3.ravel()) 

# ëª¨ë¸ ìƒì„± ë°©ë²• 3-1) - sub classing API ì‚¬ìš©, ë ˆì´ì–´ í´ë˜ìŠ¤ ë…¸ì¶œí•˜ê¸°
from tensorflow.keras.layers import Layer
# ì‚¬ìš©ì ì •ì˜ ì¸µ ì‘ì„±ìš© 
# ê¸°ì¡´ Dense ë ˆì´ì–´ì™€ ë™ì¼í•œ ê¸°ëŠ¥ì„ í•˜ëŠ” ë‚˜ë§Œì˜ ë ˆì´ì–´ë¥¼ ì§ì ‘ ë§Œë“œëŠ” ê²ƒì…ë‹ˆë‹¤!
# ì¼€ë¼ìŠ¤ì˜ layers íŒ¨í‚¤ì§€ì— ì •ì˜ëœ ë ˆì´ì–´ ëŒ€ì‹ 
# , ìƒˆë¡œìš´ ì—°ì‚°ì„ í•˜ëŠ” ë ˆì´ì–´ í˜¹ì€ í¸ì˜ë¥¼ìœ„í•´ ì—¬ëŸ¬ ë ˆì´ì–´ë¥¼ í•˜ë‚˜ë¡œ ë¬¶ì€ ë ˆì´ì–´ë¥¼ êµ¬í˜„í•  ë•Œ ì‚¬ìš© ê°€ëŠ¥
class MyLinear(Layer):
    def __init__(self,units=1,**kwargs): # ì•„ê·œë¨¼íŠ¸ ë°›ì•„ì•¼í•˜ëŠ”ë° dictí˜•íƒœë¡œ ë°›ì•„ì•¼í•¨ **kwargs
        super(MyLinear,self).__init__(**kwargs) 
        
        #ì—¬ê¸°ì— ì—¬ëŸ¬ ë ˆì´ì–´ë¥¼ í•˜ë‚˜ë¡œ ë¬¶ì€ ë ˆì´ì–´ë¥¼ êµ¬í˜„
        self.units=units  # ì¶œë ¥ ë‰´ëŸ° ìˆ˜ 
        
    # ë‚´ë¶€ì ìœ¼ë¡œ call í˜¸ì¶œ, ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜(w)ê´€ë ¨ ë‚´ìš© ê¸°ìˆ 
    def build(self,input_shape):  
        print('build',input_shape)
        self.w=self.add_weight(shape=(input_shape[-1],self.units)
            ,initializer='random_normal',trainable=True) # ì…ë ¥ í¬ê¸° ëª¨ë¥¼ë•ŒëŠ” -1 
        # ,trainable=True ë°± í”„ë¡œí¼ê²Œì´ì…˜ ì§€ì›í•˜ë ¤ë©´ ì´ê±° ì„ ì–¸í•´ì•¼í•¨
        self.b=self.add_weight(shape=(self.units,)
            ,initializer='zeros',trainable=True)
    
# êµ¬ë¶„	í•˜ì´í¼íŒŒë¼ë¯¸í„° |	ë°±í”„ë¡œí¼ê²Œì´ì…˜
# ì£¼ì²´	ğŸ‘¨â€ğŸ’» ì‚¬ëŒì´ ì„¤ì •	|ğŸ¤– ì»´í“¨í„°ê°€ ìë™ ì‹¤í–‰
# ì‹œì 	í•™ìŠµ ì „	|í•™ìŠµ ì¤‘
# ëŒ€ìƒ	ëª¨ë¸ êµ¬ì¡°, í•™ìŠµ ì„¤ì •	|ê°€ì¤‘ì¹˜(w), í¸í–¥(b)
# ëª©ì 	ëª¨ë¸ ì„±ëŠ¥ ì¡°ì •	|ì˜¤ì°¨ ìµœì†Œí™”
# ë³€ê²½	ìˆ˜ë™ìœ¼ë¡œ íŠœë‹	|ìë™ìœ¼ë¡œ ì—…ë°ì´íŠ¸
        
# ì •ì˜ëœ ê°’ë“¤ì„ ì´ìš©í•´ í•´ë‹¹ì¸µì˜ ë¡œì§ì„ ì •ì˜
    def call(self,inputs): 
        return tf.matmul(inputs,self.w)+self.b  # ì„ í˜•íšŒê·€ì‹

class MyMlp(Model):
    def __init__(self,**kwargs):
        super(MyMlp,self).__init__(**kwargs)
        self.linear1=MyLinear(2)  # íˆë“ 
        self.linear2=MyLinear(1)   # ì•„ì›ƒí’‹

    def call(self,inputs):
        x=self.linear1(inputs)
        x=tf.nn.relu(x)  # í™œì„±í™” í•¨ìˆ˜
        return self.linear2(x) # ë¦¬ë‹ˆì–´1ì„ ì™„ì„±í•˜ê³  ë¦¬ë‹ˆì–´2ë¡œ ë„˜ê¹€

model4=MyMlp()
opti4=optimizers.SGD(learning_rate=0.001)  # í™•ë¥ ì  ê²½ì‚¬í•˜ê°•ë²•  
model4.compile(optimizer=opti4,loss='mse',metrics=['mse'])  # ì”ì°¨ì— ëŒ€í•´ì„œ í‰ê· ì„ ì·¨í•œê°’ì„. 
# ì¶”ì¸¡ê°’ ì˜ˆì¸¡ê°’ì— ëŒ€í•œ ì •í™•ì„±ì„ ..í• ë•Œ mse ëŠ” 0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì¢‹ìŒ  

# í•™ìŠµì§„í–‰í• ë•Œ lossê°’ í™•ì¸í•˜ê³ ì‹¶ìœ¼ë©´ íˆìŠ¤í† ë¦¬
history4=model4.fit(x_data,y_data,epochs=100,batch_size=1,verbose=0) # ë‰´ëŸ´ë„¤íŠ¸ì›Œí¬ëŠ” ë¡œì§€ìŠ¤í‹±ë¦¬ê·¸ë ˆì…˜ì—ì„œ ë§ì´ ë•„ë‹¤
loss_metrics4=model4.evaluate(x=x_data,y=y_data,verbose=0)  # í•™ìŠµ/ê²€ì¦ ë°ì´í„°ë¥¼ ë‚˜ëˆ„ì§€ ì•Šì•˜ìœ¼ë‹ˆê¹Œ. í•™ìŠµ í›„ í‰ê°€
print('loss_metrics:',loss_metrics4)  # loss_metrics: [mse, mse]

# ì„±ëŠ¥í™•ì¸í•´ë³´ê¸° 
from sklearn.metrics import r2_score 
y_pred4=model4.predict(x_data)  # ì˜ˆì¸¡ê°’ 
print('ì„¤ëª…ë ¥:',r2_score(y_data,y_pred4))
print('ì‹¤ì œê°’:',y_data.ravel())
print('ì˜ˆì¸¡:',y_pred4.ravel()) 