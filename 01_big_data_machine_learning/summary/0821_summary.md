# 08/21 수업 내용 정리

---

## 1. 비율검정(Proportion Test)
- **일원 비율 검정(One-sample proportion test)**  
  한 집단의 비율이 특정 기준(예: 50%)과 통계적으로 다른지 검정합니다.

- **이원 비율 검정(Two-sample proportion test)**  
  두 집단의 비율이 서로 다른지 통계적으로 비교합니다.

### 예시
- 신제품 만족도 조사에서 전체 중 만족 응답 비율이 70%가 넘는지 확인
- 남성과 여성의 합격률 차이가 통계적으로 유의미한지 비교

> 비율검정은 데이터가 이항(성공/실패, 찬성/반대 등) 형태일 때 주로 사용합니다.

---

## 2. 분산(Variance)
**분산**: 분산은 데이터가 평균에서 얼마나 떨어져 흩어져 있는지를 나타내는 값
### 분산 공식

- **표본 분산**  
  $$
  s^2 = \frac{1}{n-1} \sum_{i=1}^{n} (x_i - \bar{x})^2
  $$
- **전체 분산**  
  $$
  \sigma^2 = \frac{1}{n} \sum_{i=1}^{n} (x_i - \mu)^2
  $$

---

## 3. 공분산(Covariance)
**공분산**: 공분산은 두 변수의 변화가 서로 어떤 방향으로 관련되어 있는지 나타내는 값

### 특징
- **양수**: 두 변수는 같은 방향으로 움직임 (함께 증가하거나 함께 감소)
- **음수**: 두 변수는 반대 방향으로 움직임 (한 변수는 증가, 다른 변수는 감소)
- **0에 가까움**: 두 변수 사이에 특별한 선형적 관계가 없음

### 공분산 공식
$$
\text{Cov}(X, Y) = \frac{1}{n} \sum_{i=1}^{n} (x_i - \mu_X)(y_i - \mu_Y)
$$

> 공분산은 단위의 영향을 받으므로, 값의 크기만으로 관계의 강도를 비교하기 어렵습니다.  
> 그래서 공분산을 표준화한 값인 **상관계수(Correlation Coefficient)**를 많이 사용합니다.

---

## 4. 상관계수(Correlation Coefficient)
**상관계수**: 상관계수는 두 변수 사이의 선형적 관계의 강도와 방향을 나타내는 값입니다. 공분산을 표준화한 값으로, -1에서 1 사이의 값을 가집니다.

### 특징
- **1에 가까울수록**: 두 변수는 강한 양의 선형 관계 (함께 증가)
- **-1에 가까울수록**: 두 변수는 강한 음의 선형 관계 (한 변수는 증가, 다른 변수는 감소)
- **0에 가까울수록**: 두 변수 사이에 선형적 관계가 거의 없음

### 공식
$$
r = \frac{\text{Cov}(X, Y)}{\sigma_X \sigma_Y}
$$
- $\text{Cov}(X, Y)$: X와 Y의 공분산
- $\sigma_X$, $\sigma_Y$: X와 Y의 표준편차

> 상관계수는 단위에 영향을 받지 않으므로, 서로 다른 단위의 변수 간에도 관계의 강도를 비교할 수 있습니다.

---

## 5. 최소 제곱법(Least Squares Method)란?

최소 제곱법은 데이터와 모델(직선, 곡선 등) 사이의 오차(실제 값과 예측 값의 차이)의 제곱합을 최소화하여  
가장 잘 맞는 모델을 찾는 통계적 방법입니다.

- **목적**: 데이터의 분포에 가장 잘 맞는 직선이나 곡선을 구함
- **활용**: 회귀 분석, 선형대수, 머신러닝 등 다양한 분야에서 사용됨

### 원리
각 데이터의 실제 값과 모델이 예측한 값의 차이를 제곱해서 모두 더한 값(오차 제곱합, SSE)을 최소로 만드는 모델의 파라미터(기울기, 절편 등)를 찾습니다.

### 공식
$$
SSE = \sum_{i=1}^{n} (y_i - \hat{y}_i)^2
$$
- $y_i$: 실제 값
- $\hat{y}_i$: 모델이 예측한 값

> 최소 제곱법은 데이터의 잡음이나 이상치에 영향을 받을 수 있지만,  
> 기본적인 데이터 적합 방법으로 널리 사용됩니다.

---

## 6. 회귀(Regression)란?

회귀는 한 변수(독립 변수)가 다른 변수(종속 변수)에 어떤 영향을 주는지,  
두 변수 사이의 관계를 수식으로 표현하는 방법입니다.

- **목적**: 변수 간의 관계를 파악하고, 한 변수로 다른 변수를 예측하거나 설명함
- **활용**: 통계, 데이터 분석, 머신러닝 등 다양한 분야에서 사용됨

### 예시
- 집 크기(x)로 집값(y)을 예측
- 광고비(x)로 매출액(y)을 예측

### 기본 공식(단순 선형 회귀)
$$
y = wx + b
$$
- $y$: 종속 변수(예측값)
- $x$: 독립 변수(입력값)
- $w$: 기울기(회귀 계수)
- $b$: 절편

> 회귀는 데이터의 경향성을 파악하고 미래 값을 예측하는 데 매우 유용합니다.

---

## 7. 회귀 분석(Regression Analysis)란?

### 참고
선형회귀 분석의 기본 이해(https://cafe.daum.net/flowlife/SBU0/29)

회귀 분석은 한 변수(독립 변수)가 다른 변수(종속 변수)에 어떤 영향을 미치는지,  
두 변수 사이의 관계를 수식(모델)으로 표현하는 통계적 분석 방법입니다.

- **목적**: 변수들 간의 관계를 파악하고, 한 변수로 다른 변수를 예측하거나 설명함
- **활용**: 경제, 사회, 자연과학, 머신러닝 등 다양한 분야에서 사용됨

### 종류
- **단순 회귀 분석**: 독립 변수와 종속 변수 각각 1개씩
- **다중 회귀 분석**: 여러 개의 독립 변수와 1개의 종속 변수

### 기본 공식(단순 선형 회귀)
$$
y = wx + b
$$
- $y$: 종속 변수(예측값)
- $x$: 독립 변수(입력값)
- $w$: 기울기(회귀 계수)
- $b$: 절편

> 회귀 분석을 통해 변수 간의 인과관계, 예측 모델, 트렌드 분석 등을 수행할 수 있습니다.

---

## 8. y = wx + b의 중요성

### 참고
y = wx + b 의 중요성(https://cafe.daum.net/flowlife/SBU0/66)

$y = wx + b$는 **선형 회귀**의 기본 공식으로, 입력값 $x$에 대해 기울기 $w$와 절편 $b$를 곱하고 더해서 결과값 $y$를 예측합니다.

- **기본적인 예측 모델**: 데이터의 경향성을 직선으로 표현하여, 입력값이 주어졌을 때 결과값을 쉽게 예측할 수 있습니다.
- **머신러닝의 기초**: 대부분의 머신러닝 모델(로지스틱 회귀, 신경망 등)은 이 선형 결합을 기본 구조로 사용합니다.
- **확장성**: 다중 변수(다중 선형 회귀)나 비선형 변환(딥러닝)에서도 이 구조가 핵심적으로 활용됩니다.

> $y = wx + b$는 데이터 분석, 예측, 분류 등 다양한 분야에서 가장 기본이 되는 수식입니다.

---

## 9. 로지스틱 회귀 → 트랜스포머 → LLM의 발전 구조

- **로지스틱 회귀(Logistic Regression)**:  
  머신러닝의 기초적인 분류 모델로, 입력값의 선형 결합을 통해 결과를 확률로 변환하여 이진 분류 문제를 해결합니다.

- **트랜스포머(Transformer)**:  
  2017년 등장한 딥러닝 모델로, 자연어 처리(NLP)에서 혁신을 일으켰습니다.  
  입력 데이터의 모든 위치를 서로 연결해 정보를 효율적으로 처리하며, 대규모 데이터 학습에 적합합니다.

- **LLM(Large Language Model)**:  
  트랜스포머 구조를 기반으로 한 대형 언어 모델(예: GPT, BERT 등)입니다.  
  방대한 텍스트 데이터를 학습해 자연어 이해, 생성, 번역 등 다양한 작업을 수행할 수 있습니다.

> 머신러닝의 기본 모델(로지스틱 회귀)에서 시작해, 트랜스포머의 혁신을 거쳐,  
> 현재는 LLM이 인공지능 분야의 핵심 기술로 자리잡고 있습니다.

---

## 10. 기타
- 알고리즘 시험은 해당 시험 기간에 프로젝트를 진행해야 하므로 쉽게 낼 예정입니다.
- 9월에는 팀을 구성하고, 미니 프로젝트를 하면서 호흡을 맞춰봅니다.
- 9월부터 전통적인 머신러닝부터 시작해서 인공 신경망, 딥러닝에 가서 케라스를 갖고 네트워크 형성하는 내용을 학습합니다.
- 파이토치가 아닌 텐서플로를 사용합니다.
- 미니 프로젝트를 할 때는 오전에는 수업, 오후에는 프로젝트를 진행하며, 시간이 지날수록 수업하는 시간이 짧아지고 프로젝트 시간이 길어집니다.
- 멘토를 만나는 주간에는 전체 회의를 하고 나서 멘토를 만납니다.