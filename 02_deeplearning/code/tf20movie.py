# ì˜í™” ë¦¬ë·° ì´ì§„ ë¶„ë¥˜

# imdb datasset ë¶ˆëŸ¬ì˜¤ê¸°
from tensorflow.keras.datasets import imdb
import os
import tensorflow as tf
import matplotlib.pyplot as plt
import numpy as np
from tensorflow.keras import models, layers, regularizers
os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"

print("TensorFlow ë²„ì „:", tf.__version__)
print("Keras ë°ì´í„°ì…‹ ê²½ë¡œ í™•ì¸ ì¤‘...")

# Windowsì—ì„œ Keras ë°ì´í„°ì…‹ ê²½ë¡œ í™•ì¸
keras_cache_dir = os.path.expanduser('~/.keras')
datasets_dir = os.path.join(keras_cache_dir, 'datasets')

print(f"Keras ìºì‹œ ë””ë ‰í† ë¦¬: {keras_cache_dir}")
print(f"ë°ì´í„°ì…‹ ë””ë ‰í† ë¦¬: {datasets_dir}")

# ë””ë ‰í† ë¦¬ ì¡´ìž¬ ì—¬ë¶€ í™•ì¸
if os.path.exists(datasets_dir):
    print(f"\në°ì´í„°ì…‹ ë””ë ‰í† ë¦¬ ë‚´ìš©:")
    for item in os.listdir(datasets_dir):
        item_path = os.path.join(datasets_dir, item)
        if os.path.isfile(item_path):
            size = os.path.getsize(item_path) / (1024*1024)  # MB ë‹¨ìœ„
            print(f"  ðŸ“„ {item} ({size:.2f} MB)")
        else:
            print(f"  ðŸ“ {item}/")
else:
    print("ë°ì´í„°ì…‹ ë””ë ‰í† ë¦¬ê°€ ì•„ì§ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

print("\nIMDB ë°ì´í„°ì…‹ ë¡œë”© ì¤‘... (ì²˜ìŒ ì‹¤í–‰ì‹œ ë‹¤ìš´ë¡œë“œë©ë‹ˆë‹¤)")
(train_data, train_label), (test_data, test_label) = imdb.load_data(num_words=10000)

print(f"\nâœ… ë°ì´í„° ë¡œë”© ì™„ë£Œ!")
print(train_data[0])  # ì²« ë²ˆì§¸ ë¦¬ë·°ì˜ ë‹¨ì–´ ì¸ë±ìŠ¤ ì‹œí€€ìŠ¤
print(train_label[0])
print(f"í›ˆë ¨ ë°ì´í„°: {len(train_data[0])}ê°œ")

# ì°¸ê³ : ë¦¬ë·° ë°ì´í„° í•˜ë‚˜ë¥¼ ì›ëž˜ ì˜ì–´ ë‹¨ì–´ë¡œ ë³´ê¸°
word_index = imdb.get_word_index()
print(word_index)
print(word_index.items())
reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])
print(reverse_word_index)

for i, (k, v) in enumerate(sorted(reverse_word_index.items(), key=lambda x: x[0])):
    if i >= 10:
        break
    print(k, ":", v)

decoded_review = ' '.join([reverse_word_index.get(i) for i in train_data[1]])
print(decoded_review)

# reverse_word_index = dict([(value, key) for (key, value) in imdb.get_word_index().items()])
# print("ì²« ë²ˆì§¸ ë¦¬ë·°ì˜ ì›ëž˜ ì˜ì–´ ë‹¨ì–´:")
# print(" ".join([reverse_word_index.get(i - 3, "?") for i in train_data[0]]))

# ë°ì´í„° ì¤€ë¹„
def vector_seq(sequences, dim = 10000):
    results = np.zeros((len(sequences), dim))
    for i, seq in enumerate(sequences): # í¬ê¸°ê°€ (len(sequences), dim)ì¸ 2ì°¨ì› ë°°ì—´
        results[i, seq] = 1.  # í•´ë‹¹ ë‹¨ì–´ ì¸ë±ìŠ¤ ìœ„ì¹˜ë¥¼ 1ë¡œ ì„¤ì •
    return results

x_train = vector_seq(train_data)
x_test = vector_seq(test_data)
print(x_train, ' ', x_train.shape)
y_train = train_label.astype('float32')
y_test = test_label.astype('float32')
print(y_train, ' ', y_train.shape)

# ëª¨ë¸ ìž‘ì„±

model = models.Sequential()
model.add(layers.Input(shape=(10000, )))
model.add(layers.Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.001)))
model.add(layers.Dense(16, activation='relu'))
model.add(layers.Dense(1, activation='sigmoid'))

model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])
print(model.summary())

# validation data ì¤€ë¹„
x_val = x_train[:10000]
partial_x_train = x_train[10000:]
y_val = y_train[:10000]
partial_y_train = y_train[10000:]
print(len(x_val), ' ', len(partial_x_train))
history = model.fit(partial_x_train, partial_y_train, epochs=30, batch_size=512, validation_data=(x_val, y_val), verbose=2)

# í›ˆë ¨ê³¼ ê²€ì¦ ì†ì‹¤ / ì •í™•ë„ì— ëŒ€í•œ ì‹œê°í™”
history_dict = history.history
print(history_dict.keys())
loss = history_dict['loss']
val_loss = history_dict['val_loss']
epochs = range(1, len(loss) + 1)

plt.plot(epochs, loss, 'bo', label='Training loss')
plt.plot(epochs, val_loss, 'r', label='Validation loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

plt.clf() # ê·¸ëž˜í”„ ì´ˆê¸°í™”
acc = history_dict['acc']
val_acc = history_dict['val_acc']
epochs = range(1, len(loss) + 1)

plt.plot(epochs, acc, 'bo', label='Training acc')
plt.plot(epochs, val_acc, 'r', label='Validation acc')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()
plt.clf() # ê·¸ëž˜í”„ ì´ˆê¸°í™”
plt.close() # ê·¸ëž˜í”„ ì°½ ë‹«ê¸°

pred = model.predict(x_test[:5])
print('ì˜ˆì¸¡ê°’ : ', np.where(pred >= 0.5, 1, 0).ravel())
print('ì‹¤ì œê°’ : ', y_test[:5])