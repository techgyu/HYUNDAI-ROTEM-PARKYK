
# 08/01 수업 + 코딩 주요 개념 요약
---
## 1. 오늘의 목표

- 벡터의 개념과 연산(크기, 덧셈, 내적 등) 이해
- 내적이 실제로 어떻게 계산되고, 어떤 의미를 가지는지 예시와 함께 익히기
---
## 2. 스칼라와 벡터, 속력과 속도의 차이

### 2.1 스칼라(Scalar)와 벡터(Vector)란?

- **스칼라**: 크기만 있는 물리량 (예: 속력, 질량, 온도)
- **벡터**: 크기와 방향이 모두 있는 물리량 (예: 속도, 힘, 가속도)

### 2.2 속력과 속도의 차이

- **속력**: 물체가 이동한 거리(경로의 총 길이)를 걸린 시간으로 나눈 값. 방향과 무관, 크기만 있음. (예: 시속 80km)
- **속도**: 물체의 위치 변화(변위)를 걸린 시간으로 나눈 값. 크기와 방향 모두 포함. (예: 동쪽으로 시속 80km)
---
## 3. 벡터의 표기, 연산, 예시

### 3.1 벡터의 표기
- 보통 화살표(→) 또는 굵은 글씨로 표기: \( \vec{v} \), **v**
- 벡터의 크기(절댓값): \( |\vec{v}| \), \( ||\vec{v}|| \)

### 3.2 벡터 연산
- 여러 데이터(값)들을 벡터로 보고, 덧셈, 내적 등 다양한 연산 수행

### 3.3 벡터의 예시
- 2차원 벡터: (3, 4) → 크기: \( \sqrt{3^2 + 4^2} = 5 \)
- 3차원 벡터: (1, 2, 2) → 크기: \( \sqrt{1^2 + 2^2 + 2^2} = 3 \)
---
## 4. 내적(Dot Product, 점곱)

- 두 벡터 \( \vec{a} = (a_1, a_2, ..., a_n) \), \( \vec{b} = (b_1, b_2, ..., b_n) \)의 내적: \( a_1b_1 + a_2b_2 + ... + a_nb_n \)
- 내적의 결과는 스칼라(숫자)
- 내적은 두 벡터가 이루는 각의 코사인값과 각 벡터의 크기를 곱한 것과 같음: \( \vec{a} \cdot \vec{b} = |\vec{a}| |\vec{b}| \cos\theta \)
- 내적은 두 벡터의 방향 유사성, 투영 등을 나타낼 때 사용
---
## 5. 넘파이의 차원 (Numpy Array의 차원)

넘파이(NumPy)는 파이썬에서 수치 계산을 할 때 사용하는 대표적인 라이브러리로, 다양한 차원의 배열(array)을 다룰 수 있습니다. 배열의 차원은 데이터가 어떻게 구조화되어 있는지를 나타냅니다.

| 차원 | 명칭         | 구조 예시                        | 용어(수학) | 실제 예시                      |
|------|--------------|----------------------------------|------------|-------------------------------|
| 1차원 | 벡터         | [1, 2, 3, 4]                     | Vector     | 학생들의 시험 점수 목록         |
| 2차원 | 행렬         | [[1, 2, 3], [4, 5, 6]]           | Matrix     | 여러 학생의 여러 과목 점수      |
| 3차원 | 행렬의 집합  | [[[1, 2], [3, 4]], [[5, 6], [7, 8]]] | 3D Array   | 흑백 이미지 여러 장 데이터      |

> **정리:**
> - 1차원: [a, b, c, ...] (벡터)
> - 2차원: [[a, b], [c, d], ...] (행렬)
> - 3차원: [[[a, b], [c, d]], [[e, f], [g, h]], ...] (행렬의 집합)
---
## 6. 벡터, 매트릭스, 텐서의 차원과 관계 (Vector, Matrix, Tensor)

벡터, 매트릭스, 텐서는 데이터의 구조와 차원을 표현하는 기본 단위입니다. 차원이 높아질수록 더 복잡하고 많은 정보를 담을 수 있습니다.

### 6.1 벡터(Vector)
- 1차원 배열(리스트)로, 여러 개의 수(값)를 한 줄로 나열한 구조입니다.
- 예시: [1, 2, 3, 4] (학생들의 시험 점수 목록)

### 6.2 매트릭스(Matrix)
- 2차원 배열로, 여러 개의 벡터(행 또는 열)를 한데 모아 만든 표 형태의 구조입니다.
- 예시: [[1, 2, 3], [4, 5, 6]] (여러 학생의 여러 과목 점수)
- 즉, 벡터 여러 개를 세로/가로로 쌓으면 매트릭스가 됩니다.

### 6.3 텐서(Tensor)
- 3차원 이상(3D, 4D, ...)의 다차원 배열을 의미합니다.
- 예시: [[[1, 2], [3, 4]], [[5, 6], [7, 8]]] (흑백 이미지 여러 장 데이터)
- 즉, 매트릭스 여러 개를 쌓으면 텐서가 됩니다.
- 4차원 텐서: 컬러 이미지 여러 장(이미지, 채널, 행, 열 등)

| 차원 | 명칭/구조         | 예시 값         | 실제 데이터 예시                |
|------|-------------------|-----------------|---------------------------------|
| 0D   | 점(스칼라)        | 5               | 단일 값(온도, 키 등)            |
| 1D   | 벡터              | [2]             | 키, 몸무게 등 단일 특성 데이터  |
| 2D   | 매트릭스(행렬)    | [[1,2],[3,4]]   | 여러 학생의 여러 과목 점수      |
| 3D   | 텐서(3D 배열)     | [[[1,2],[3,4]], [[5,6],[7,8]]] | 흑백 이미지 여러 장 데이터      |
| 4D   | 텐서(4D 배열)     | (예시 생략)     | 컬러 이미지 여러 장(배치, 채널, 행, 열) |

> **정리:**
> - 벡터 여러 개를 모으면 매트릭스(2D 배열), 매트릭스 여러 개를 모으면 텐서(3D 이상 배열)가 됩니다.
> - 텐서는 딥러닝, 이미지 처리 등에서 대용량 데이터를 다룰 때 필수적으로 사용됩니다.
---
## 7. 벡터 공간(Vector Space)

벡터 공간은 벡터들이 모여 있는 집합으로, 벡터 연산(덧셈, 스칼라 곱 등)이 정의되어 있는 수학적 구조입니다. 벡터 공간의 모든 원소(점)는 벡터이며, 다음과 같은 조건을 만족해야 합니다.

### 7.1 벡터 공간의 조건
- 임의의 두 벡터의 덧셈 결과도 벡터 공간에 속한다 (덧셈에 대해 닫혀 있음)
- 임의의 벡터와 스칼라(숫자)의 곱도 벡터 공간에 속한다 (스칼라 곱에 대해 닫혀 있음)
- 0벡터(모든 성분이 0인 벡터)가 존재한다
- 벡터 덧셈, 스칼라 곱에 대해 결합법칙, 분배법칙 등이 성립한다

### 7.2 예시
- 2차원 평면상의 모든 벡터의 집합 (예: (x, y) 형태의 모든 벡터)
- 3차원 공간상의 모든 벡터의 집합 (예: (x, y, z) 형태의 모든 벡터)
- n차원 실수 벡터의 집합 (\( \mathbb{R}^n \))

### 7.3 데이터 분석과 벡터 공간
- 데이터 분석에서는 여러 특성(피처)로 이루어진 데이터 한 줄(샘플)을 n차원 벡터로 보고, 전체 데이터셋을 n차원 벡터 공간으로 생각합니다.
- 벡터 공간 개념을 통해 데이터 간의 거리, 방향, 투영, 차원 축소 등 다양한 수학적 처리가 가능합니다.
---
## 8. 2개의 벡터의 합 (벡터 덧셈)

### 8.1 벡터 덧셈의 개념
두 벡터의 합은 각 성분별로 더하는 방식으로 계산합니다. 2차원 공간에서 벡터 A와 벡터 B의 합은 다음과 같습니다.

- 벡터 A = [A1, A2]
- 벡터 B = [B1, B2]
- 벡터 A + 벡터 B = [A1+B1, A2+B2]

### 8.2 도식적 예시
벡터 A와 벡터 B를 평면에 화살표로 그렸을 때, 벡터 A의 끝점에서 벡터 B를 시작하면 두 벡터의 합은 시작점에서 끝점까지의 벡터(대각선)로 나타낼 수 있습니다. 이를 '평행사변형 법칙'이라고도 합니다.

예시
- 벡터 A = [2, 1], 벡터 B = [1, 3]
- 벡터 A + 벡터 B = [2+1, 1+3] = [3, 4]

### 8.3 데이터 분석에서의 활용 예시
데이터 분석에서는 여러 특성(피처) 값을 벡터로 보고, 두 데이터의 합을 구할 때 벡터 덧셈을 사용합니다.

예시
- 고객1의 특성: [나이, 구매횟수] = [30, 5]
- 고객2의 특성: [40, 2]
- 두 고객의 특성 합: [30+40, 5+2] = [70, 7]
---
## 9. 나중에 배울 것

### 9.1 Word to Vector (단어의 벡터화)
- 단어를 컴퓨터가 이해할 수 있도록 수치 벡터로 변환하는 방법입니다. 대표적으로 Word2Vec, GloVe, FastText 등이 있습니다.
- 예를 들어, "king"이라는 단어가 [0.25, 0.13, ...]처럼 100차원, 200차원 등 고차원 벡터로 표현됩니다.
- 이렇게 벡터로 변환하면 단어 간의 의미적 유사성, 관계 등을 수치적으로 계산할 수 있습니다.

### 9.2 코사인 유사도 (Cosine Similarity)
- 두 벡터가 이루는 각의 코사인값을 이용해 유사도를 측정하는 방법입니다.
- 수식: \( \cos(\theta) = \frac{\vec{a} \cdot \vec{b}}{||\vec{a}|| \cdot ||\vec{b}||} \)
- 값의 범위는 -1 ~ 1이며, 1에 가까울수록 두 벡터(단어)가 비슷한 의미를 가집니다.
- 예시: "king"과 "queen"의 벡터가 비슷한 방향을 가진다면, 코사인 유사도 값이 1에 가까워집니다.

### 9.3 벡터 연산을 통한 단어 관계 추론
- 벡터의 덧셈/뺄셈을 통해 단어 간의 의미적 관계를 수치적으로 표현할 수 있습니다.
- 예시: king - man + woman = queen
  - 'king'에서 'man'의 의미를 빼고 'woman'을 더하면 'queen'과 가장 가까운 벡터가 나옵니다.
- 이런 방식으로 단어 간의 관계(예: 남자-여자, 나라-수도 등)를 유추할 수 있습니다.

### 9.4 벡터 데이터베이스 (Vector Database)
- 수많은 벡터(문서, 이미지, 단어 등)를 저장하고, 주어진 벡터와 가장 가까운 벡터(유사한 의미)를 빠르게 찾아주는 데이터베이스입니다.
- 예시: 이미지 검색, 문서 검색, 추천 시스템 등에서 활용됩니다.
- 원리: 모든 데이터를 벡터로 변환한 뒤, 코사인 유사도 등으로 가장 가까운 벡터를 찾아 결과로 반환합니다.

> **정리:**
> - 단어, 문서, 이미지 등 다양한 데이터를 벡터로 변환하면, 수치적으로 유사성/관계/검색이 가능해집니다.
> - 코사인 유사도와 벡터 연산을 통해 의미적 관계를 파악하고, 벡터 데이터베이스를 활용해 대규모 데이터에서 유사한 항목을 빠르게 찾을 수 있습니다.
---

## 10. 선형 결합, 선형 독립, 선형 종속

### 10.1 선형 결합 (Linear Combination)
- 여러 벡터에 각각 상수(스칼라)를 곱한 뒤 더하는 연산을 말합니다.
- 예시: 벡터 A, B가 있을 때, 2A + 3B와 같이 각 벡터에 상수를 곱해서 더할 수 있습니다.
- 수식: \( c_1\vec{v}_1 + c_2\vec{v}_2 + ... + c_n\vec{v}_n \) (여기서 c는 상수, v는 벡터)
- 벡터에 2를 곱하면 크기가 2배로 늘어나고, -1을 곱하면 방향이 반대가 됩니다.

### 10.2 벡터 관계: 선형 독립 (Linear Independence)
- 여러 벡터 중에서, 어떤 벡터도 나머지 벡터들의 선형 결합으로 표현할 수 없다면 '선형 독립'이라고 합니다.
- 즉, 한 벡터가 다른 벡터들의 조합으로 만들어질 수 없을 때 선형 독립입니다.
- 예시: (1,0), (0,1)은 서로 선형 독립입니다. (2,3)은 (1,0), (0,1)로 표현할 수 있지만, (1,0), (0,1) 자체는 서로 조합해서 만들 수 없습니다.

### 10.3 벡터 관계: 선형 종속 (Linear Dependence)
- 여러 벡터 중에서, 어떤 벡터가 나머지 벡터들의 선형 결합으로 표현될 수 있다면 '선형 종속'입니다.
- 즉, 한 벡터가 다른 벡터들의 조합으로 만들어질 수 있을 때 선형 종속입니다.
- 예시: (2,4)는 (1,2)의 2배이므로, 두 벡터는 선형 종속입니다.

#### 정리 및 활용
- 선형 독립/종속 개념은 벡터 공간의 차원(기저 벡터 개수)과 관련이 깊으며, 데이터 분석, 머신러닝, 차원 축소(예: PCA) 등에서 매우 중요하게 사용됩니다.

---

## 11. mpg dataset

### mpg(miles per gallon, mpg) dataset 이란?:

자동차의 연비(miles per gallon, mpg)와 관련된 다양한 정보를 담고 있는 대표적인 예제 데이터셋입니다. 주로 통계, 데이터 분석, 머신러닝 입문에서 많이 사용됩니다.

### 주요 특징
- 각 행(row)은 한 대의 자동차 정보를 나타냅니다.
- 주요 컬럼(변수):
  - mpg: 연비 (갤런당 마일)
  - cylinders: 실린더 개수
  - displacement: 배기량
  - horsepower: 마력
  - weight: 차량 무게
  - acceleration: 가속력
  - model year: 연식
  - origin: 제조국(미국, 유럽, 일본 등)
  - name: 자동차 이름


### 예시 데이터 (표)

| mpg | cylinders | displacement | horsepower | weight | acceleration | model year | origin | name                 |
|-----|-----------|--------------|------------|--------|--------------|------------|--------|----------------------|
| 18  | 8         | 307          | 130        | 3504   | 12.0         | 70         | usa    | chevrolet chevelle  |
| 15  | 8         | 350          | 165        | 3693   | 11.5         | 70         | usa    | buick skylark 320   |
| 36  | 4         | 91           | 69         | 2130   | 14.7         | 82         | japan  | honda civic         |
| 27  | 4         | 97           | 88         | 2130   | 14.5         | 70         | europe | vw type 3           |
| 24  | 4         | 113          | 95         | 2228   | 14.0         | 71         | usa    | ford pinto          |


### 활용 예시 (상세)
- **연비와 변수 간의 관계 분석**: 무게, 배기량, 마력 등과 연비(mpg) 사이의 상관관계를 시각화(산점도, 상관계수 등)로 분석할 수 있습니다.
- **회귀분석(선형/비선형)**: 연비를 예측하는 회귀모델(선형회귀, 다항회귀 등)을 만들고, 변수의 영향력을 해석할 수 있습니다.
- **분류(Classification)**: 예를 들어, 연비가 높은 차/낮은 차로 구분하는 분류 문제에 활용할 수 있습니다.
- **결측치 처리**: horsepower 등 일부 변수에 결측치가 포함되어 있어, 결측치 처리(평균 대체, 삭제 등) 실습에 적합합니다.
- **데이터 전처리**: 범주형 변수(제조국, 이름 등) 인코딩, 이상치 탐지, 정규화 등 다양한 전처리 실습이 가능합니다.
- **데이터 시각화**: 히스토그램, 박스플롯, 페어플롯 등 다양한 시각화 기법을 적용해 볼 수 있습니다.
- **차원 축소(PCA, 주성분분석)**: 여러 변수(무게, 배기량, 마력 등)를 소수의 주성분으로 축소하여 데이터의 구조를 시각화하거나, 분석의 효율을 높일 수 있습니다.
  - 예시: 7~8개의 수치형 변수를 2~3개의 주성분으로 줄여 2D/3D 산점도로 시각화
- **클러스터링(군집분석)**: 비슷한 특성을 가진 자동차끼리 그룹화(군집화)하여, 시장 세분화나 특성 분석에 활용할 수 있습니다.
- **머신러닝 실습**: 지도학습(회귀, 분류), 비지도학습(PCA, 클러스터링) 등 다양한 머신러닝 알고리즘 실습에 적합합니다.

> **참고:**
> - 파이썬의 seaborn, statsmodels, R 등에서 내장 데이터셋으로 쉽게 불러올 수 있습니다.

---

## 12. 초평면
### 초평면(Hyperplane)이란?

- 초평면은 n차원 공간에서 (n-1)차원의 평면을 의미합니다.
  - 2차원 공간의 초평면: 1차원 직선
  - 3차원 공간의 초평면: 2차원 평면
  - 4차원 이상 공간의 초평면: 3차원 이상의 평면(직관적으로 그릴 수 없음)

- 수식으로는 다음과 같이 표현됩니다.
  - \( w_1x_1 + w_2x_2 + ... + w_nx_n + b = 0 \)
  - 여기서 w는 각 축의 계수(가중치), x는 변수, b는 절편(바이어스)

### 예시
- 2차원: x + y = 1 (직선)
- 3차원: x + y + z = 1 (평면)

### 데이터 분석/머신러닝에서의 활용
- 초평면은 데이터를 분리하거나(분류), 투영하거나(차원 축소)할 때 자주 등장합니다.
- 대표적으로 SVM(서포트 벡터 머신)에서 데이터를 두 그룹으로 나누는 경계선(결정 경계)이 바로 초평면입니다.
- PCA(주성분분석)에서도 데이터의 분산이 가장 큰 방향(주성분)을 기준으로 초평면에 데이터를 "투영"해 차원을 축소합니다.
  - 여기서 "투영"이란, 고차원 공간에 있는 데이터를 초평면(낮은 차원 공간)에 그림자처럼 내려놓는 것(=비추어 옮기는 것)입니다.
  - 예를 들어, 3차원 공간의 점들을 2차원 평면(초평면)에 가장 잘 펼쳐지도록 눌러서 옮기는 것과 같습니다.
  - 이렇게 하면 데이터의 주요 특성(정보)을 최대한 보존하면서 차원을 줄일 수 있습니다.
  - 투영은 데이터의 구조를 시각화하거나, 분석을 더 쉽게 할 때 매우 유용하게 사용됩니다.

**정리:**
- 초평면은 고차원 공간에서 데이터를 나누거나 투영하는 데 핵심적인 역할을 하며, 머신러닝/통계/수학 등 다양한 분야에서 매우 중요하게 사용됩니다.

---

## 13. 내적
두 벡터의 내적은 크기*방향 유사도를 동시에 측정하는 연산이다.
- 두 벡터가 얼마나 같은 방향을 가리키고 있는가

### 삼각함수 코사인

#### 코사인(Cosine) 함수란?
- 삼각함수 중 하나로, 각(세타, θ)의 크기에 따라 직각삼각형의 밑변과 빗변의 비율을 나타냅니다.
- 정의: \( \cos(\theta) = \frac{\text{밑변}}{\text{빗변}} \ )
- 즉, 빗변이 A, 밑변이 B라면 \( \cos(\theta) = B/A \ )

#### 주요 공식 및 변형
- \( B = A \times \cos(\theta) \ )
- \( A = B / \cos(\theta) \ )
- 코사인 값의 범위: -1 ~ 1 (삼각형에서는 0 ~ 1)

#### 각도별 코사인 값 예시
- \( \cos(0°) = 1 \ ) : 완전히 같은 방향
- \( \cos(60°) = 0.5 \ )
- \( \cos(90°) = 0 \ ) : 완전히 수직
- \( \cos(180°) = -1 \ ) : 완전히 반대 방향

#### 내적과의 관계
- 두 벡터의 내적은 두 벡터의 크기와 두 벡터가 이루는 각의 코사인값을 곱한 것과 같습니다.
- \( \vec{a} \cdot \vec{b} = |\vec{a}| |\vec{b}| \cos(\theta) \ )
- 즉, 코사인 값이 1에 가까울수록 두 벡터는 같은 방향, 0이면 수직, -1이면 반대 방향입니다.

> **정리:**
> - 코사인 함수는 각의 크기에 따라 두 선분(벡터)의 방향 관계를 수치로 표현합니다.
> - 내적 계산, 벡터의 유사도, 데이터 분석 등 다양한 분야에서 매우 중요하게 사용됩니다.