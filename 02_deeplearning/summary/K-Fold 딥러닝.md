# K-Foldë¥¼ ì´ìš©í•œ ë”¥ëŸ¬ë‹

## ğŸ“– K-Fold êµì°¨ ê²€ì¦ì´ë€?

K-Fold êµì°¨ ê²€ì¦(Cross Validation)ì€ ë°ì´í„°ë¥¼ Kê°œì˜ í´ë“œ(fold)ë¡œ ë‚˜ëˆ„ì–´ ê°ê°ì„ ê²€ì¦ ì„¸íŠ¸ë¡œ ì‚¬ìš©í•˜ë©´ì„œ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ëŠ” ê¸°ë²•ì…ë‹ˆë‹¤. ì´ëŠ” í•œì •ëœ ë°ì´í„°ì—ì„œ ëª¨ë¸ì˜ ì¼ë°˜í™” ì„±ëŠ¥ì„ ë” ì •í™•í•˜ê²Œ ì¸¡ì •í•  ìˆ˜ ìˆëŠ” ë°©ë²•ì…ë‹ˆë‹¤.

## ğŸ”„ K-Fold ì‘ë™ ì›ë¦¬

### 1. ë°ì´í„° ë¶„í• 
- ì „ì²´ ë°ì´í„°ë¥¼ Kê°œì˜ ë™ì¼í•œ í¬ê¸°ì˜ í´ë“œë¡œ ë¶„í• 
- ì¼ë°˜ì ìœ¼ë¡œ K=5 ë˜ëŠ” K=10ì„ ë§ì´ ì‚¬ìš©

### 2. ë°˜ë³µ í•™ìŠµ ë° ê²€ì¦
```
Fold 1: [Test] [Train] [Train] [Train] [Train]
Fold 2: [Train] [Test] [Train] [Train] [Train]
Fold 3: [Train] [Train] [Test] [Train] [Train]
Fold 4: [Train] [Train] [Train] [Test] [Train]
Fold 5: [Train] [Train] [Train] [Train] [Test]
```

### 3. ì„±ëŠ¥ í‰ê· í™”
- Kë²ˆì˜ í•™ìŠµ/ê²€ì¦ì„ í†µí•´ ì–»ì€ ì„±ëŠ¥ ì§€í‘œë“¤ì˜ í‰ê· ì„ ìµœì¢… ì„±ëŠ¥ìœ¼ë¡œ ì‚¬ìš©

## ğŸ¯ ë”¥ëŸ¬ë‹ì—ì„œ K-Foldì˜ ì¥ì 

### 1. **ë°ì´í„° í™œìš© ê·¹ëŒ€í™”**
- ëª¨ë“  ë°ì´í„°ê°€ í›ˆë ¨ê³¼ ê²€ì¦ì— ëª¨ë‘ ì‚¬ìš©ë¨
- íŠ¹íˆ ë°ì´í„°ê°€ ë¶€ì¡±í•œ ìƒí™©ì—ì„œ ìœ ìš©

### 2. **ì‹ ë¢°ì„± ìˆëŠ” ì„±ëŠ¥ í‰ê°€**
- ë‹¨ì¼ train/test ë¶„í• ë³´ë‹¤ ë” ì•ˆì •ì ì¸ ì„±ëŠ¥ ì¸¡ì •
- ë°ì´í„° ë¶„í• ì— ë”°ë¥¸ ì„±ëŠ¥ ë³€ë™ì„± ê°ì†Œ

### 3. **ê³¼ì í•© ê°ì§€**
- ì—¬ëŸ¬ í´ë“œì—ì„œì˜ ì„±ëŠ¥ ë¶„ì‚°ì„ í†µí•´ ëª¨ë¸ì˜ ì•ˆì •ì„± í™•ì¸
- ì¼ê´€ë˜ì§€ ì•Šì€ ì„±ëŠ¥ íŒ¨í„´ ë°œê²¬ ê°€ëŠ¥

### 4. **í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹**
- ê° í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°í•©ì— ëŒ€í•´ ì‹ ë¢°ì„± ìˆëŠ” ì„±ëŠ¥ í‰ê°€
- ìµœì ì˜ ëª¨ë¸ ì„¤ì • ì„ íƒì— ë„ì›€

## âš ï¸ ë”¥ëŸ¬ë‹ì—ì„œ K-Foldì˜ ì£¼ì˜ì‚¬í•­

### 1. **ê³„ì‚° ë¹„ìš©**
- ë”¥ëŸ¬ë‹ ëª¨ë¸ì€ í•™ìŠµ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦¼
- Kë²ˆì˜ í•™ìŠµìœ¼ë¡œ ì¸í•œ ì‹œê°„ ì¦ê°€ (Kë°°)

### 2. **ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰**
- ì—¬ëŸ¬ ëª¨ë¸ì„ ë™ì‹œì— ì €ì¥í•´ì•¼ í•  ìˆ˜ ìˆìŒ
- GPU ë©”ëª¨ë¦¬ ê´€ë¦¬ í•„ìš”

### 3. **ì‹œê³„ì—´ ë°ì´í„°**
- ì‹œê°„ ìˆœì„œê°€ ì¤‘ìš”í•œ ë°ì´í„°ì—ì„œëŠ” ì í•©í•˜ì§€ ì•ŠìŒ
- TimeSeriesSplit ë“± ë‹¤ë¥¸ ë°©ë²• ê³ ë ¤ í•„ìš”

## ğŸ› ï¸ êµ¬í˜„ ë°©ë²•

### 1. Scikit-learn í™œìš©
```python
from sklearn.model_selection import KFold, StratifiedKFold
from sklearn.model_selection import cross_val_score

# ê¸°ë³¸ K-Fold
kfold = KFold(n_splits=5, shuffle=True, random_state=42)

# ë¶„ë¥˜ ë¬¸ì œì—ì„œ í´ë˜ìŠ¤ ë¹„ìœ¨ ìœ ì§€
skfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
```

### 2. ìˆ˜ë™ êµ¬í˜„
```python
def manual_kfold_cv(model_fn, X, y, k=5):
    fold_size = len(X) // k
    scores = []
    
    for i in range(k):
        # ê²€ì¦ ì„¸íŠ¸ ì¸ë±ìŠ¤
        val_start = i * fold_size
        val_end = (i + 1) * fold_size
        
        # ë°ì´í„° ë¶„í• 
        X_val = X[val_start:val_end]
        y_val = y[val_start:val_end]
        X_train = np.concatenate([X[:val_start], X[val_end:]])
        y_train = np.concatenate([y[:val_start], y[val_end:]])
        
        # ëª¨ë¸ í•™ìŠµ ë° í‰ê°€
        model = model_fn()
        model.fit(X_train, y_train)
        score = model.evaluate(X_val, y_val)
        scores.append(score)
    
    return np.mean(scores), np.std(scores)
```

## ğŸ“Š ì„±ëŠ¥ í‰ê°€ ë° ë¶„ì„

### 1. **í‰ê·  ì„±ëŠ¥**
```python
mean_accuracy = np.mean(cv_scores)
print(f"í‰ê·  ì •í™•ë„: {mean_accuracy:.4f}")
```

### 2. **ì„±ëŠ¥ ë¶„ì‚°**
```python
std_accuracy = np.std(cv_scores)
print(f"ì •í™•ë„ í‘œì¤€í¸ì°¨: {std_accuracy:.4f}")
```

### 3. **ì‹ ë¢°êµ¬ê°„**
```python
confidence_interval = 1.96 * std_accuracy / np.sqrt(k)
print(f"95% ì‹ ë¢°êµ¬ê°„: {mean_accuracy:.4f} Â± {confidence_interval:.4f}")
```

## ğŸ¨ ì‹œê°í™”

### 1. **í´ë“œë³„ ì„±ëŠ¥ ë¹„êµ**
```python
plt.figure(figsize=(10, 6))
plt.bar(range(1, k+1), cv_scores)
plt.axhline(y=np.mean(cv_scores), color='red', linestyle='--', label='í‰ê· ')
plt.xlabel('Fold')
plt.ylabel('Accuracy')
plt.title('K-Fold Cross Validation Results')
plt.legend()
plt.show()
```

### 2. **ë°•ìŠ¤ í”Œë¡¯**
```python
plt.boxplot(cv_scores)
plt.ylabel('Accuracy')
plt.title('K-Fold Performance Distribution')
```

## ğŸš€ ì‹¤ì „ í™œìš© íŒ

### 1. **ì ì ˆí•œ K ê°’ ì„ íƒ**
- ì‘ì€ ë°ì´í„°ì…‹: K=5 ë˜ëŠ” K=10
- í° ë°ì´í„°ì…‹: K=3 ë˜ëŠ” K=5
- ë§¤ìš° ì‘ì€ ë°ì´í„°ì…‹: Leave-One-Out (K=N)

### 2. **ë¶„ì¸µ ìƒ˜í”Œë§ ì‚¬ìš©**
- ë¶„ë¥˜ ë¬¸ì œì—ì„œ í´ë˜ìŠ¤ ë¶ˆê· í˜•ì´ ìˆì„ ë•Œ
- StratifiedKFold ì‚¬ìš© ê¶Œì¥

### 3. **ëœë¤ ì‹œë“œ ê³ ì •**
- ì¬í˜„ ê°€ëŠ¥í•œ ê²°ê³¼ë¥¼ ìœ„í•´ random_state ì„¤ì •
- ë‹¤ë¥¸ ì‹¤í—˜ê³¼ì˜ ê³µì •í•œ ë¹„êµ

### 4. **ì¡°ê¸° ì¢…ë£Œì™€ í•¨ê»˜ ì‚¬ìš©**
```python
early_stopping = EarlyStopping(
    monitor='val_loss',
    patience=10,
    restore_best_weights=True
)
```

## ï¿½ K-Fold vs ì¼ë°˜ Validation ë¹„êµ

### ğŸ“Š ì‹œê°ì  ë¹„êµ

#### 1. **ì¼ë°˜ Hold-out Validation (Train/Test Split)**
```
ì „ì²´ ë°ì´í„°: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ]
ë¶„í•  ê²°ê³¼:   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ]
             â†      Train (70%)      â†’ â† Test (30%) â†’

ï¿½ğŸ“ˆ 1ë²ˆë§Œ í‰ê°€: Accuracy = 85.2%
```

**íŠ¹ì§•:**
- ë°ì´í„°ë¥¼ í•œ ë²ˆë§Œ ë¶„í•  (ì˜ˆ: 70% í›ˆë ¨, 30% í…ŒìŠ¤íŠ¸)
- ë¹ ë¥´ê³  ê°„ë‹¨í•˜ì§€ë§Œ **ìš´ì— ë”°ë¼ ê²°ê³¼ê°€ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŒ**
- í…ŒìŠ¤íŠ¸ ë°ì´í„°ëŠ” í•™ìŠµì— ì „í˜€ ì‚¬ìš©ë˜ì§€ ì•ŠìŒ (ë°ì´í„° ë‚­ë¹„)

#### 2. **K-Fold Cross Validation (K=5)**
```
ì „ì²´ ë°ì´í„°: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ]

Fold 1: [â–ˆâ–ˆâ–ˆâ–ˆ] [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ]
        â† Valâ†’ â†           Train            â†’
        
Fold 2: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] [â–ˆâ–ˆâ–ˆâ–ˆ] [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ]
        â† Train â†’ â† Valâ†’ â†        Train        â†’
        
Fold 3: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] [â–ˆâ–ˆâ–ˆâ–ˆ] [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ]
        â†   Train   â†’ â† Valâ†’ â†     Train     â†’
        
Fold 4: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] [â–ˆâ–ˆâ–ˆâ–ˆ] [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ]
        â†     Train       â†’ â† Valâ†’ â† Train â†’
        
Fold 5: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] [â–ˆâ–ˆâ–ˆâ–ˆ]
        â†        Train          â†’ â† Valâ†’

ğŸ“ˆ 5ë²ˆ í‰ê°€: Accuracy = [84.1%, 86.3%, 85.7%, 84.9%, 85.2%]
ğŸ“Š ìµœì¢… ê²°ê³¼: 85.24% Â± 0.78%
```

**íŠ¹ì§•:**
- ëª¨ë“  ë°ì´í„°ê°€ í›ˆë ¨ê³¼ ê²€ì¦ì— ëª¨ë‘ ì‚¬ìš©ë¨
- ë” ì‹ ë¢°ì„± ìˆëŠ” ì„±ëŠ¥ í‰ê°€ (í‘œì¤€í¸ì°¨ë„ í•¨ê»˜ ì œê³µ)
- ê³„ì‚° ì‹œê°„ì´ Kë°° ì¦ê°€

### ğŸ“ˆ ì„±ëŠ¥ ì•ˆì •ì„± ë¹„êµ

#### ì‹¤í—˜ ì‹œë‚˜ë¦¬ì˜¤: ê°™ì€ ë°ì´í„°ë¡œ 10ë²ˆ ë°˜ë³µ ì‹¤í—˜

```python
# ì¼ë°˜ Train/Test Splitì„ 10ë²ˆ ë°˜ë³µ
hold_out_results = []
for i in range(10):
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=i)
    model.fit(X_train, y_train)
    accuracy = model.evaluate(X_test, y_test)
    hold_out_results.append(accuracy)

print("Hold-out ê²°ê³¼:", hold_out_results)
print("í‰ê· :", np.mean(hold_out_results))
print("í‘œì¤€í¸ì°¨:", np.std(hold_out_results))
```

**ê²°ê³¼ ì˜ˆì‹œ:**
```
Hold-out ê²°ê³¼: [0.823, 0.867, 0.841, 0.798, 0.885, 0.829, 0.856, 0.812, 0.874, 0.835]
í‰ê· : 0.842
í‘œì¤€í¸ì°¨: 0.025 (ë†’ì€ ë³€ë™ì„±!)
```

```python
# K-Fold Cross Validation
from sklearn.model_selection import cross_val_score

kfold_results = cross_val_score(model, X, y, cv=5, scoring='accuracy')
print("K-Fold ê²°ê³¼:", kfold_results)
print("í‰ê· :", np.mean(kfold_results))
print("í‘œì¤€í¸ì°¨:", np.std(kfold_results))
```

**ê²°ê³¼ ì˜ˆì‹œ:**
```
K-Fold ê²°ê³¼: [0.841, 0.863, 0.857, 0.849, 0.852]
í‰ê· : 0.852
í‘œì¤€í¸ì°¨: 0.008 (ë‚®ì€ ë³€ë™ì„±!)
```

### ğŸ¯ ì–¸ì œ ì–´ë–¤ ë°©ë²•ì„ ì‚¬ìš©í• ê¹Œ?

#### **ì¼ë°˜ Hold-out Validation ì‚¬ìš© ì‹œê¸°**
```python
# ëŒ€ìš©ëŸ‰ ë°ì´í„° (100ë§Œê°œ ì´ìƒ)
if len(dataset) > 1_000_000:
    use_hold_out = True
    
# ê³„ì‚° ìì›ì´ ì œí•œì ì¼ ë•Œ
if gpu_memory < 8_GB or time_limit < 1_hour:
    use_hold_out = True
    
# ë¹ ë¥¸ í”„ë¡œí† íƒ€ì´í•‘
if development_phase == "initial_testing":
    use_hold_out = True
```

#### **K-Fold Cross Validation ì‚¬ìš© ì‹œê¸°**
```python
# ì¤‘ì†Œ ê·œëª¨ ë°ì´í„° (10ë§Œê°œ ì´í•˜)
if len(dataset) < 100_000:
    use_kfold = True
    
# ì‹ ë¢°ì„± ìˆëŠ” ì„±ëŠ¥ í‰ê°€ê°€ í•„ìš”í•  ë•Œ
if final_model_evaluation or paper_submission:
    use_kfold = True
    
# í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹
if hyperparameter_tuning:
    use_kfold = True
```

### ğŸ“Š ì‹œê°í™”ë¡œ ë³´ëŠ” ì°¨ì´ì 

```python
import matplotlib.pyplot as plt
import numpy as np

# ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ìƒì„±
np.random.seed(42)
hold_out_scores = np.random.normal(0.842, 0.025, 50)  # ë†’ì€ ë³€ë™ì„±
kfold_scores = np.random.normal(0.852, 0.008, 50)     # ë‚®ì€ ë³€ë™ì„±

fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))

# Hold-out ê²°ê³¼
ax1.hist(hold_out_scores, bins=15, alpha=0.7, color='skyblue', edgecolor='black')
ax1.axvline(np.mean(hold_out_scores), color='red', linestyle='--', linewidth=2, label=f'í‰ê· : {np.mean(hold_out_scores):.3f}')
ax1.set_title('Hold-out Validation\n(ë†’ì€ ë³€ë™ì„±)', fontsize=14, fontweight='bold')
ax1.set_xlabel('Accuracy')
ax1.set_ylabel('Frequency')
ax1.legend()
ax1.grid(True, alpha=0.3)

# K-Fold ê²°ê³¼
ax2.hist(kfold_scores, bins=15, alpha=0.7, color='lightgreen', edgecolor='black')
ax2.axvline(np.mean(kfold_scores), color='red', linestyle='--', linewidth=2, label=f'í‰ê· : {np.mean(kfold_scores):.3f}')
ax2.set_title('K-Fold Cross Validation\n(ë‚®ì€ ë³€ë™ì„±)', fontsize=14, fontweight='bold')
ax2.set_xlabel('Accuracy')
ax2.set_ylabel('Frequency')
ax2.legend()
ax2.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
```

### ğŸ’¡ í•µì‹¬ ì°¨ì´ì  ìš”ì•½

| ë¹„êµ í•­ëª© | Hold-out Validation | K-Fold Cross Validation |
|-----------|--------------------|-----------------------|
| **ë°ì´í„° í™œìš©** | 70-80% (í›ˆë ¨ìš©) | 100% (ëª¨ë“  ë°ì´í„° í™œìš©) |
| **ì‹ ë¢°ì„±** | ë¶„í• ì— ë”°ë¼ ë³€ë™ í¼ | ì•ˆì •ì ì´ê³  ì‹ ë¢°ì„± ë†’ìŒ |
| **ê³„ì‚° ì‹œê°„** | ë¹ ë¦„ (1ë²ˆ í•™ìŠµ) | ëŠë¦¼ (Kë²ˆ í•™ìŠµ) |
| **í‘œì¤€í¸ì°¨** | ì œê³µë˜ì§€ ì•ŠìŒ | ì„±ëŠ¥ ë¶„ì‚° ì •ë³´ ì œê³µ |
| **ì ìš© ìƒí™©** | ëŒ€ìš©ëŸ‰ ë°ì´í„°, ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ | ì •í™•í•œ í‰ê°€, í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ |
| **ê³¼ì í•© ê°ì§€** | ì–´ë ¤ì›€ | ì—¬ëŸ¬ í´ë“œì—ì„œ ì¼ê´€ì„± í™•ì¸ |

### ğŸ”¬ ì‹¤ì œ ì˜ˆì œë¡œ í™•ì¸í•˜ê¸°

```python
# í”¼ë§ˆ ì¸ë””ì–¸ ë‹¹ë‡¨ë³‘ ë°ì´í„°ë¡œ ì‹¤í—˜
from sklearn.datasets import load_diabetes
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, cross_val_score

# ë°ì´í„° ë¡œë“œ
X, y = load_diabetes(return_X_y=True)
y = (y > np.median(y)).astype(int)  # ì´ì§„ ë¶„ë¥˜ë¡œ ë³€í™˜

# 1. Hold-out Validation
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
model = RandomForestClassifier(random_state=42)
model.fit(X_train, y_train)
hold_out_accuracy = model.score(X_test, y_test)

print(f"Hold-out Accuracy: {hold_out_accuracy:.4f}")

# 2. K-Fold Cross Validation
kfold_scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')
kfold_mean = np.mean(kfold_scores)
kfold_std = np.std(kfold_scores)

print(f"K-Fold Accuracy: {kfold_mean:.4f} Â± {kfold_std:.4f}")
print(f"K-Fold ê° í´ë“œ: {kfold_scores}")
```

ì´ë ‡ê²Œ ë³´ë©´ K-Foldê°€ ë” ì•ˆì •ì ì´ê³  ì‹ ë¢°ì„± ìˆëŠ” í‰ê°€ë¥¼ ì œê³µí•œë‹¤ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤! ğŸ¯

| ë°©ë²• | ì¥ì  | ë‹¨ì  | ì‚¬ìš© ì‹œê¸° |
|------|------|------|-----------|
| **Hold-out** | ë¹ ë¥´ê³  ê°„ë‹¨ | ë°ì´í„° ë‚­ë¹„, ë¶ˆì•ˆì • | ëŒ€ìš©ëŸ‰ ë°ì´í„° |
| **K-Fold** | ì•ˆì •ì , ëª¨ë“  ë°ì´í„° í™œìš© | ê³„ì‚° ë¹„ìš© ë†’ìŒ | ì¤‘ì†Œ ê·œëª¨ ë°ì´í„° |
| **Leave-One-Out** | ìµœëŒ€í•œ ë°ì´í„° í™œìš© | ë§¤ìš° ëŠë¦¼, ë†’ì€ ë¶„ì‚° | ë§¤ìš° ì‘ì€ ë°ì´í„° |
| **Bootstrap** | ë‹¤ì–‘í•œ ìƒ˜í”Œë§ | ë³µì¡í•¨, í¸í–¥ ê°€ëŠ¥ | í†µê³„ì  ë¶„ì„ í•„ìš” |

## ğŸ’¡ ê²°ë¡ 

K-Fold êµì°¨ ê²€ì¦ì€ ë”¥ëŸ¬ë‹ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ì‹ ë¢°ì„± ìˆê²Œ í‰ê°€í•˜ëŠ” í•µì‹¬ ê¸°ë²•ì…ë‹ˆë‹¤. ê³„ì‚° ë¹„ìš©ì´ ì¦ê°€í•˜ì§€ë§Œ, íŠ¹íˆ ë°ì´í„°ê°€ ì œí•œì ì¸ ìƒí™©ì—ì„œ ëª¨ë¸ì˜ ì¼ë°˜í™” ì„±ëŠ¥ì„ ì •í™•íˆ ì¸¡ì •í•˜ê³  ê³¼ì í•©ì„ ë°©ì§€í•˜ëŠ” ë° ë§¤ìš° ìœ ìš©í•©ë‹ˆë‹¤. í”„ë¡œì íŠ¸ì˜ íŠ¹ì„±ê³¼ ê°€ìš© ìì›ì„ ê³ ë ¤í•˜ì—¬ ì ì ˆíˆ í™œìš©í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.